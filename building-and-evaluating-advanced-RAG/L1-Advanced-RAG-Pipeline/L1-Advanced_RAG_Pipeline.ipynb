{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd962005",
   "metadata": {},
   "source": [
    "source: https://learn.deeplearning.ai/building-evaluating-advanced-rag/lesson/2/advanced-rag-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c61cf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T02:38:48.867291Z",
     "start_time": "2023-12-04T02:38:15.444562Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b993ba71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T01:02:57.318840Z",
     "start_time": "2023-12-05T01:02:41.433348Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (2.1.1)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: filelock in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from sentence-transformers) (4.35.2)\n",
      "Requirement already satisfied: tqdm in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torchvision in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from sentence-transformers) (0.16.1)\n",
      "Requirement already satisfied: numpy in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from sentence-transformers) (1.26.2)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.3.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.11.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: nltk in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from sentence-transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from sentence-transformers) (0.19.4)\n",
      "Requirement already satisfied: requests in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: click in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from torchvision->sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/r337555/anaconda3/envs/llama/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
      "Using cached scikit_learn-1.3.2-cp310-cp310-macosx_10_9_x86_64.whl (10.2 MB)\n",
      "Using cached scipy-1.11.4-cp310-cp310-macosx_10_9_x86_64.whl (37.3 MB)\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: sentencepiece, threadpoolctl, scipy, scikit-learn, sentence-transformers\n",
      "Successfully installed scikit-learn-1.3.2 scipy-1.11.4 sentence-transformers-2.2.2 sentencepiece-0.1.99 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bff53e",
   "metadata": {},
   "source": [
    "# Lesson 1: Advanced RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb98470-c136-471d-a63e-d50d8eb09c57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T01:03:16.459393Z",
     "start_time": "2023-12-05T01:03:10.278454Z"
    },
    "height": 98,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e2859b-596e-40b3-867b-f4d6e91f74bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T01:03:19.175939Z",
     "start_time": "2023-12-05T01:03:17.973257Z"
    },
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7d0857-b9d1-4feb-8243-bfd2f4953acd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T01:03:19.900874Z",
     "start_time": "2023-12-05T01:03:19.896254Z"
    },
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "41 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Doc ID: 5e8e6147-10e5-4be1-abfe-5dba2fad1f55\n",
      "Text: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\n",
      "How to  Build Your Career in AIA Simple Guide\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3123d3d",
   "metadata": {},
   "source": [
    "## Basic RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4abc806-64f5-46bb-8c9f-6469ecb18d20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:54:05.422779Z",
     "start_time": "2023-12-05T00:54:05.419011Z"
    },
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc2baff-5e8b-4733-9899-16f248777b23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:54:33.140515Z",
     "start_time": "2023-12-05T00:54:18.795118Z"
    },
    "height": 183,
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "index = VectorStoreIndex.from_documents([document],\n",
    "                                        service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae52a26c-7d0c-44df-8043-4c7f19f794b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:54:36.923947Z",
     "start_time": "2023-12-05T00:54:36.920739Z"
    },
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0d5b6e-cc2e-4648-b28c-5fa25a97d175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:54:52.224251Z",
     "start_time": "2023-12-05T00:54:45.986866Z"
    },
    "height": 81,
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When finding projects to build your experience, there are several steps you can take. First, you can join existing projects by asking to join someone else's project if they have an idea. Additionally, you can develop a side hustle or personal project that may or may not develop into something bigger. It's important to choose projects that will help you grow technically, but are also challenging enough to stretch your skills without being too difficult. Having good teammates or people to discuss things with is also important, as you can learn a lot from the people around you. Finally, consider if the project can be a stepping stone to larger projects in terms of technical complexity and business impact.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are steps to take when finding projects to build your experience?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50a1ac5",
   "metadata": {},
   "source": [
    "## Evaluation setup using TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ead7dc1-71b2-4001-918f-bf8d610fd3fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:55:39.047443Z",
     "start_time": "2023-12-05T00:55:39.041883Z"
    },
    "height": 132,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the keys to building a career in AI?\n",
      "How can teamwork contribute to success in AI?\n",
      "What is the importance of networking in AI?\n",
      "What are some good habits to develop for a successful career?\n",
      "How can altruism be beneficial in building a career?\n",
      "What is imposter syndrome and how does it relate to AI?\n",
      "Who are some accomplished individuals who have experienced imposter syndrome?\n",
      "What is the first step to becoming good at AI?\n",
      "What are some common challenges in AI?\n",
      "Is it normal to find parts of AI challenging?\n"
     ]
    }
   ],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a278f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:56:21.963253Z",
     "start_time": "2023-12-05T00:56:21.960194Z"
    },
    "height": 64
   },
   "outputs": [],
   "source": [
    "# You can try your own question:\n",
    "new_question = \"What is the right AI job for me?\"\n",
    "eval_questions.append(new_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d5204e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:56:24.551169Z",
     "start_time": "2023-12-05T00:56:24.547460Z"
    },
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are the keys to building a career in AI?', 'How can teamwork contribute to success in AI?', 'What is the importance of networking in AI?', 'What are some good habits to develop for a successful career?', 'How can altruism be beneficial in building a career?', 'What is imposter syndrome and how does it relate to AI?', 'Who are some accomplished individuals who have experienced imposter syndrome?', 'What is the first step to becoming good at AI?', 'What are some common challenges in AI?', 'Is it normal to find parts of AI challenging?', 'What is the right AI job for me?']\n"
     ]
    }
   ],
   "source": [
    "print(eval_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c063c9c7-bf1e-4b24-9a22-d4281c0f954e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:56:33.016308Z",
     "start_time": "2023-12-05T00:56:32.929265Z"
    },
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦑 Tru initialized with db url sqlite:///default.sqlite .\n",
      "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f754bed-d16f-4c8d-a1a1-b36096272570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:57:07.509230Z",
     "start_time": "2023-12-05T00:57:07.354063Z"
    },
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_prebuilt_trulens_recorder\n",
    "\n",
    "tru_recorder = get_prebuilt_trulens_recorder(query_engine,\n",
    "                                             app_id=\"Direct Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dbdfbcc-aac7-4805-9894-4fc016c66bf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:58:00.771754Z",
     "start_time": "2023-12-05T00:57:13.743686Z"
    },
    "height": 64,
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "with tru_recorder as recording:\n",
    "    for question in eval_questions:\n",
    "        response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e14f512b-601c-42d0-bfac-bf41d9c577e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:58:11.845837Z",
     "start_time": "2023-12-05T00:58:11.793588Z"
    },
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2da4a602-0d56-4bf8-9fa6-03ef0b7e254b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:58:13.963181Z",
     "start_time": "2023-12-05T00:58:13.908674Z"
    },
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_8415dab2945969dd3f3ad916606fc526</td>\n",
       "      <td>\"What are the keys to building a career in AI?\"</td>\n",
       "      <td>\"The keys to building a career in AI are learn...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_8415dab2945969dd3f3...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-04T21:57:13.808189\", \"...</td>\n",
       "      <td>2023-12-04T21:57:18.774338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[{'args': {'prompt': 'What are the keys to bui...</td>\n",
       "      <td>[{'args': {'prompt': 'What are the keys to bui...</td>\n",
       "      <td>[{'args': {'source': 'PAGE 1Founder, DeepLearn...</td>\n",
       "      <td>4</td>\n",
       "      <td>2091</td>\n",
       "      <td>0.003174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_f58434efbff009481806de8932e15379</td>\n",
       "      <td>\"How can teamwork contribute to success in AI?\"</td>\n",
       "      <td>\"Collaborating and working in teams is crucial...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_f58434efbff00948180...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-04T21:57:19.063208\", \"...</td>\n",
       "      <td>2023-12-04T21:57:23.788375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>[{'args': {'prompt': 'How can teamwork contrib...</td>\n",
       "      <td>[{'args': {'prompt': 'How can teamwork contrib...</td>\n",
       "      <td>[{'args': {'source': 'Hopefully the previous c...</td>\n",
       "      <td>4</td>\n",
       "      <td>1711</td>\n",
       "      <td>0.002609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_e06ff56c2b2f8959f7015136d271a445</td>\n",
       "      <td>\"What is the importance of networking in AI?\"</td>\n",
       "      <td>\"Networking is important in AI because it allo...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_e06ff56c2b2f8959f70...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-04T21:57:24.004526\", \"...</td>\n",
       "      <td>2023-12-04T21:57:28.599263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[{'args': {'prompt': 'What is the importance o...</td>\n",
       "      <td>[{'args': {'prompt': 'What is the importance o...</td>\n",
       "      <td>[{'args': {'source': 'Hopefully the previous c...</td>\n",
       "      <td>4</td>\n",
       "      <td>1704</td>\n",
       "      <td>0.002596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_a8b80b7f5506b0d1b83ffede2ba936bb</td>\n",
       "      <td>\"What are some good habits to develop for a su...</td>\n",
       "      <td>\"Developing good habits is crucial for a succe...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_a8b80b7f5506b0d1b83...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-04T21:57:28.783284\", \"...</td>\n",
       "      <td>2023-12-04T21:57:33.468238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[{'args': {'prompt': 'What are some good habit...</td>\n",
       "      <td>[{'args': {'prompt': 'What are some good habit...</td>\n",
       "      <td>[{'args': {'source': 'Hopefully the previous c...</td>\n",
       "      <td>4</td>\n",
       "      <td>1681</td>\n",
       "      <td>0.002564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_4374279a46b32663d1154b0d75df8165</td>\n",
       "      <td>\"How can altruism be beneficial in building a ...</td>\n",
       "      <td>\"Altruism can be beneficial in building a care...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_4374279a46b32663d11...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-04T21:57:33.659613\", \"...</td>\n",
       "      <td>2023-12-04T21:57:36.794498</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>[{'args': {'prompt': 'How can altruism be bene...</td>\n",
       "      <td>[{'args': {'prompt': 'How can altruism be bene...</td>\n",
       "      <td>[{'args': {'source': 'Hopefully the previous c...</td>\n",
       "      <td>3</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.002563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                app_id                                           app_json  \\\n",
       "0  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "1  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "2  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "3  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "4  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "2  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "3  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "4  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_8415dab2945969dd3f3ad916606fc526   \n",
       "1  record_hash_f58434efbff009481806de8932e15379   \n",
       "2  record_hash_e06ff56c2b2f8959f7015136d271a445   \n",
       "3  record_hash_a8b80b7f5506b0d1b83ffede2ba936bb   \n",
       "4  record_hash_4374279a46b32663d1154b0d75df8165   \n",
       "\n",
       "                                               input  \\\n",
       "0    \"What are the keys to building a career in AI?\"   \n",
       "1    \"How can teamwork contribute to success in AI?\"   \n",
       "2      \"What is the importance of networking in AI?\"   \n",
       "3  \"What are some good habits to develop for a su...   \n",
       "4  \"How can altruism be beneficial in building a ...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"The keys to building a career in AI are learn...    -   \n",
       "1  \"Collaborating and working in teams is crucial...    -   \n",
       "2  \"Networking is important in AI because it allo...    -   \n",
       "3  \"Developing good habits is crucial for a succe...    -   \n",
       "4  \"Altruism can be beneficial in building a care...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_8415dab2945969dd3f3...   \n",
       "1  {\"record_id\": \"record_hash_f58434efbff00948180...   \n",
       "2  {\"record_id\": \"record_hash_e06ff56c2b2f8959f70...   \n",
       "3  {\"record_id\": \"record_hash_a8b80b7f5506b0d1b83...   \n",
       "4  {\"record_id\": \"record_hash_4374279a46b32663d11...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "1  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "2  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "3  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "4  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2023-12-04T21:57:13.808189\", \"...   \n",
       "1  {\"start_time\": \"2023-12-04T21:57:19.063208\", \"...   \n",
       "2  {\"start_time\": \"2023-12-04T21:57:24.004526\", \"...   \n",
       "3  {\"start_time\": \"2023-12-04T21:57:28.783284\", \"...   \n",
       "4  {\"start_time\": \"2023-12-04T21:57:33.659613\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2023-12-04T21:57:18.774338               1.0               0.95   \n",
       "1  2023-12-04T21:57:23.788375               1.0               0.00   \n",
       "2  2023-12-04T21:57:28.599263               1.0               0.10   \n",
       "3  2023-12-04T21:57:33.468238               1.0               0.50   \n",
       "4  2023-12-04T21:57:36.794498               1.0               0.00   \n",
       "\n",
       "   Groundedness                             Answer Relevance_calls  \\\n",
       "0          1.00  [{'args': {'prompt': 'What are the keys to bui...   \n",
       "1          0.90  [{'args': {'prompt': 'How can teamwork contrib...   \n",
       "2          0.25  [{'args': {'prompt': 'What is the importance o...   \n",
       "3          1.00  [{'args': {'prompt': 'What are some good habit...   \n",
       "4          0.74  [{'args': {'prompt': 'How can altruism be bene...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'What are the keys to bui...   \n",
       "1  [{'args': {'prompt': 'How can teamwork contrib...   \n",
       "2  [{'args': {'prompt': 'What is the importance o...   \n",
       "3  [{'args': {'prompt': 'What are some good habit...   \n",
       "4  [{'args': {'prompt': 'How can altruism be bene...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': 'PAGE 1Founder, DeepLearn...        4          2091   \n",
       "1  [{'args': {'source': 'Hopefully the previous c...        4          1711   \n",
       "2  [{'args': {'source': 'Hopefully the previous c...        4          1704   \n",
       "3  [{'args': {'source': 'Hopefully the previous c...        4          1681   \n",
       "4  [{'args': {'source': 'Hopefully the previous c...        3          1680   \n",
       "\n",
       "   total_cost  \n",
       "0    0.003174  \n",
       "1    0.002609  \n",
       "2    0.002596  \n",
       "3    0.002564  \n",
       "4    0.002563  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64310897-179b-4081-aab8-f08a3392a078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:59:14.721877Z",
     "start_time": "2023-12-05T00:59:13.376269Z"
    },
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a091e4b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T00:59:40.420642Z",
     "start_time": "2023-12-05T00:59:40.354305Z"
    }
   },
   "outputs": [],
   "source": [
    "records.to_csv('records.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eedcef",
   "metadata": {},
   "source": [
    "## Advanced RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17ea2b",
   "metadata": {},
   "source": [
    "### 1. Sentence Window retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae4a668-3699-4750-82f7-e53ae1bca3a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T01:03:27.443072Z",
     "start_time": "2023-12-05T01:03:27.344259Z"
    },
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f7678f-358d-448d-b153-11ac8e96a7fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T01:03:29.469186Z",
     "start_time": "2023-12-05T01:03:28.334125Z"
    },
    "height": 149,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_sentence_window_index\n\u001b[1;32m      3\u001b[0m sentence_index \u001b[38;5;241m=\u001b[39m build_sentence_window_index(\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mdocument\u001b[49m,\n\u001b[1;32m      5\u001b[0m     llm,\n\u001b[1;32m      6\u001b[0m     embed_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal:BAAI/bge-small-en-v1.5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'document' is not defined"
     ]
    }
   ],
   "source": [
    "from utils import build_sentence_window_index\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72f904c3-9845-4df5-9d2e-e5115160f987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T01:02:15.681552Z",
     "start_time": "2023-12-05T01:02:15.582258Z"
    },
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "('Cannot import sentence-transformers or torch package,', 'please `pip install torch sentence-transformers`')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.10/site-packages/llama_index/postprocessor/sbert_rerank.py:24\u001b[0m, in \u001b[0;36mSentenceTransformerRerank.__init__\u001b[0;34m(self, top_n, model, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_sentence_window_query_engine\n\u001b[0;32m----> 3\u001b[0m sentence_window_engine \u001b[38;5;241m=\u001b[39m \u001b[43mget_sentence_window_query_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects-Personal/DeepLearning-AI/building-and-evaluating-advanced-RAG/L1-Advanced-RAG-Pipeline/utils.py:116\u001b[0m, in \u001b[0;36mget_sentence_window_query_engine\u001b[0;34m(sentence_index, similarity_top_k, rerank_top_n)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sentence_window_query_engine\u001b[39m(\n\u001b[1;32m    110\u001b[0m     sentence_index,\n\u001b[1;32m    111\u001b[0m     similarity_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m    112\u001b[0m     rerank_top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    113\u001b[0m ):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# define postprocessors\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     postproc \u001b[38;5;241m=\u001b[39m MetadataReplacementPostProcessor(target_metadata_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m     rerank \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformerRerank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrerank_top_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBAAI/bge-reranker-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     sentence_window_engine \u001b[38;5;241m=\u001b[39m sentence_index\u001b[38;5;241m.\u001b[39mas_query_engine(\n\u001b[1;32m    121\u001b[0m         similarity_top_k\u001b[38;5;241m=\u001b[39msimilarity_top_k, node_postprocessors\u001b[38;5;241m=\u001b[39m[postproc, rerank]\n\u001b[1;32m    122\u001b[0m     )\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentence_window_engine\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.10/site-packages/llama_index/postprocessor/sbert_rerank.py:26\u001b[0m, in \u001b[0;36mSentenceTransformerRerank.__init__\u001b[0;34m(self, top_n, model, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot import sentence-transformers or torch package,\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease `pip install torch sentence-transformers`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m device \u001b[38;5;241m=\u001b[39m infer_torch_device() \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m device\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m CrossEncoder(\n\u001b[1;32m     32\u001b[0m     model, max_length\u001b[38;5;241m=\u001b[39mDEFAULT_SENTENCE_TRANSFORMER_MAX_LENGTH, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     33\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: ('Cannot import sentence-transformers or torch package,', 'please `pip install torch sentence-transformers`')"
     ]
    }
   ],
   "source": [
    "from utils import get_sentence_window_query_engine\n",
    "\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e2314-7cac-42f4-a552-9a8e4db641eb",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"how do I get started on a personal project in AI?\"\n",
    ")\n",
    "print(str(window_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c10917-8846-4e73-838d-6232c906a7db",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_sentence_window = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine,\n",
    "    app_id = \"Sentence Window Query Engine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11710e67-aba8-479e-8585-c4c611e2c1d2",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_sentence_window as recording:\n",
    "        response = sentence_window_engine.query(question)\n",
    "        print(question)\n",
    "        print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d1e55-729b-45f2-a0f9-773c49d4616f",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92d0f2-2e80-48d5-92af-b3655eb03ea2",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e2c55",
   "metadata": {},
   "source": [
    "### 2. Auto-merging retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c639b-31eb-4c34-b6c4-fe6ae5717733",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import build_automerging_index\n",
    "\n",
    "automerging_index = build_automerging_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"merging_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32265f2-0247-42df-9abe-97d52f69edcf",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_automerging_query_engine\n",
    "\n",
    "automerging_query_engine = get_automerging_query_engine(\n",
    "    automerging_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ed568-220e-4c7c-aa60-cfa58ef1fcbd",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "auto_merging_response = automerging_query_engine.query(\n",
    "    \"How do I build a portfolio of AI projects?\"\n",
    ")\n",
    "print(str(auto_merging_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f18a9-7b8a-4ae2-ab11-3a6a941a5afc",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_automerging = get_prebuilt_trulens_recorder(automerging_query_engine,\n",
    "                                                         app_id=\"Automerging Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc2cfe-7096-4fa0-aa72-094bebac35a3",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_automerging as recording:\n",
    "        response = automerging_query_engine.query(question)\n",
    "        print(question)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404dec1-60ca-42fa-ac13-793a5423aa64",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f545d41-0d98-446f-8214-8b59bef08d6c",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
